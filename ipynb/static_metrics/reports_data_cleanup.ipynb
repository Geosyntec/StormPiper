{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../stormpiper/\")\n",
    "import stormpiper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stormpiper.connections.arcgis import get_subbasins_with_equity_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str=\"postgresql+psycopg2://stormpiper:supersafety@localhost:5432/stormpiper\"\n",
    "engine = create_engine(conn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subbasin_info = pandas.read_sql(\"select * from subbasininfo_v\", con=engine)\n",
    "subbasin_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subbasin_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_fields = [\n",
    "    {\n",
    "        'field':c\n",
    "    }\n",
    "    for c in list(subbasin_info.columns)\n",
    "]\n",
    "\n",
    "result_fields_df = (\n",
    "    pandas.DataFrame(result_fields)\n",
    ")\n",
    "# result_fields_df.to_csv(f'result_fields_{datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")}.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_ix = get_subbasins_with_equity_ix()\n",
    "equity_ix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pandas.read_csv(\"./static_subbasin_metrics.csv\").rename(columns={\"SUBBASIN\": \"subbasin\"}).set_index('subbasin')\n",
    "results = (\n",
    "    results\n",
    "    .drop(columns=[c for c in results.columns if 'unnamed' in c.lower()])\n",
    "    .join(equity_ix.set_index('subbasin')[[\"access\",\t\"economic_value\",\t\"environmental_value\",\t\"livability_value\",\t\"opportunity_value\"]])\n",
    ")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_map = {\n",
    "    # industrial\n",
    "    \"Landuse Heavy Industrial\": \"INDH\",\n",
    "    \"Landuse Light Industrial\": \"INDL\",\n",
    "    # residential\n",
    "    \"Landuse Low-Scale Residential\": \"RESL\",\n",
    "    \"Landuse Mid-Scale Residential\": \"RESM\",\n",
    "    \"Landuse Multi-Family (High Density)\": \"RESMFHD\",\n",
    "    \"Landuse Airport Compatibility Residential\": \"RESAIR\",\n",
    "    # commercial\n",
    "    \"Landuse General Commercial\": \"COM\",\n",
    "    \"Landuse Neighborhood Commercial\": \"COMN\",\n",
    "    \"Landuse Neighborhood Mixed-Use Center\": \"COMNMU\",\n",
    "    \"Landuse Crossroads Mixed-Use Center\": \"COMMCMU\",\n",
    "    \"Landuse Major Institutional Campus\": \"INS\",\n",
    "    # os\n",
    "    \"Landuse Parks and Open Space\": \"OS\",\n",
    "    \"Landuse Shoreline\": \"SHORE\",\n",
    "    # growth centers\n",
    "    \"Landuse Tacoma Mall Regional Growth Center\": \"RGCTM\",\n",
    "    \"Landuse Downtown Regional Growth Center\": \"RGCD\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_fields = [\n",
    "    {\n",
    "        \"long_name\": c,\n",
    "        \"prefix\": \"lu\"\n",
    "            if \"landuse\" in c.lower()\n",
    "            else \"lc\"\n",
    "            if \"landcover\" in c.lower()\n",
    "            else \"\",\n",
    "        \"code\": lu_map.get(c, \"\"),\n",
    "        \"field_base\": lu_map.get(c, c.lower())\n",
    "        .lower()\n",
    "        .replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "        .replace(\"landuse_\", \"\")\n",
    "        .replace(\"landcover_\", \"\")\n",
    "        .replace(\"impervious\", \"imp\"),\n",
    "        \"units\": \"score\"\n",
    "            if \"age\" in c.lower()\n",
    "            else \"count\"\n",
    "            if \"discharge_points\" in c.lower()\n",
    "            else \"score\"\n",
    "            if \"pavement\" in c.lower()\n",
    "            else \"degC\"\n",
    "            if \"urban_heat\" in c.lower()\n",
    "            else \"pct\" \n",
    "            if any(k in c.lower() for k in ['landcover', \"landuse\", \"biodiversity\"])\n",
    "            else \"\",\n",
    "    }\n",
    "    for c in list(results.columns)\n",
    "]\n",
    "\n",
    "cleaned_fields_df = (\n",
    "    pandas.DataFrame(cleaned_fields)\n",
    "    .assign(field=lambda df: (df['prefix'] + \"_\" + df[\"field_base\"] + \"_\" + df[\"units\"]).str.strip(\"_\"))\n",
    "    .assign(description='')\n",
    "    .assign(results_group_short_name='')\n",
    "    .assign(results_group_display_name='')\n",
    "    .assign(priority_group_short_name='')\n",
    "    .assign(priority_group_display_name='')\n",
    ")\n",
    "\n",
    "cleaned_fields = cleaned_fields_df.to_dict(\"records\")\n",
    "\n",
    "# print(json.dumps(cleaned_fields, indent=2))\n",
    "cleaned_fields_df.to_csv(f'field_manifest_{datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_results = results.reset_index().rename(columns={m['long_name']:m['field'] for m in cleaned_fields})\n",
    "clean_results.to_csv(f'clean_static_subbasin_metrics_{datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")}.csv')\n",
    "clean_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_results[[c for c in clean_results if 'lu_' in c]].assign(_check_sum=lambda df: df.sum(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
